{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import glob\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler\n",
    "import re\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import monai\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_3D = 64\n",
    "TRAINING_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 112\n",
    "N_EPOCHS = 2\n",
    "do_valid = True\n",
    "n_workers = 0\n",
    "type_ = \"FLAIR\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    image = cv2.imread(path, 0)\n",
    "    if image is None:\n",
    "        return np.zeros(IMAGE_SIZE)\n",
    "    \n",
    "    image = cv2.resize(image, size) / 255\n",
    "    return image.astype('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainRSNADataset(Dataset):\n",
    "    def __init__(\n",
    "        self, patient_path, paths, targets, transform=None, mri_type=\"FLAIR\", is_train=True, ds_type=\"forgot\", do_load=True\n",
    "    ):\n",
    "        \n",
    "        self.patient_path = patient_path\n",
    "        self.paths = paths   \n",
    "        self.targets = targets\n",
    "        self.type = mri_type\n",
    "\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.folder = \"train\" if self.is_train else \"test\"\n",
    "        self.do_load = do_load\n",
    "        self.ds_type = ds_type        \n",
    "        \n",
    "        '''self.target = target\n",
    "        self.data = data\n",
    "        self.type = mri_type\n",
    "\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.folder = \"train\" if self.is_train else \"test\" '''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        target = self.targets[index]\n",
    "        _3d_images = self.load_images_3d(_id)\n",
    "        _3d_images = torch.tensor(_3d_images).float()\n",
    "        if self.is_train:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        else:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''row = self.data.loc[index]\n",
    "        case_id = int(row.BraTS21ID)\n",
    "        target = int(row[self.target])\n",
    "        _3d_images = self.load_dicom_images_3d(case_id)\n",
    "        _3d_images = torch.tensor(_3d_images).float()\n",
    "        if self.is_train:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        else:\n",
    "            return {\"image\": _3d_images, \"case_id\": case_id}'''\n",
    "\n",
    "\n",
    "    def load_images_3d(\n",
    "        self,\n",
    "        case_id,\n",
    "        num_imgs=NUM_IMAGES_3D,\n",
    "        img_size=IMAGE_SIZE,\n",
    "        rotate=0,\n",
    "    ):\n",
    "        case_id = str(case_id).zfill(5)\n",
    "\n",
    "        path = f\"./input/reduced_dataset/{case_id}/{self.type}/*.png\"\n",
    "        files = sorted(\n",
    "            glob.glob(path),\n",
    "            key=lambda var: [\n",
    "                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        middle = len(files) // 2\n",
    "        if len(files) <= 64:\n",
    "            image_stack = [load_image(f) for f in files]\n",
    "        else:\n",
    "            p1 = middle - 32 #max(0, middle - num_imgs2)\n",
    "            p2 = middle + 32 #min(len(files), middle + num_imgs2)\n",
    "            image_stack = [load_image(f) for f in files[p1:p2]]\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''num_imgs2 = num_imgs // 2\n",
    "        p1 = max(0, middle - num_imgs2)\n",
    "        p2 = min(len(files), middle + num_imgs2)\n",
    "        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]'''\n",
    "        \n",
    "        img3d = np.stack(image_stack).T\n",
    "        if img3d.shape[-1] < num_imgs:\n",
    "            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "            img3d = np.concatenate((img3d, n_zero), axis=-1)\n",
    "\n",
    "        if np.min(img3d) < np.max(img3d):\n",
    "            img3d = img3d - np.min(img3d)\n",
    "            img3d = img3d / np.max(img3d)\n",
    "\n",
    "        return np.expand_dims(img3d, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------deleted the empty patient data--------------------------\n",
      "train_FLAIR_1\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train EPOCH 18/2: average loss: 0.7257766565435553, Acc: 0.5292096138000488, F1 score: 0.5861027240753174  AUC SCORE = 0.5460053010223401\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test EPOCH 1/2: Validation average loss: 0.707089439034462, Accuracy: 0.5085910558700562 F1 score: 0.3914893567562103, + AUC SCORE = 0.5373212086767074 + AUC SCORE THRESH 0.5714285714285714 = 0.5498721227621485\n",
      "Saving the model...\n",
      "Train EPOCH 19/2: average loss: 0.7037133703084841, Acc: 0.5292096138000488, F1 score: 0.5910447835922241  AUC SCORE = 0.5333207118515714\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Test EPOCH 2/2: Validation average loss: 0.7183867561286443, Accuracy: 0.5326460599899292 F1 score: 0.4285714328289032, + AUC SCORE = 0.5515297906602254 + AUC SCORE THRESH 0.7551020408163265 = 0.5592497868712702\n",
      "Saving the model...\n",
      "train_FLAIR_2\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 135\u001b[0m\n\u001b[1;32m    132\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    133\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 135\u001b[0m tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    137\u001b[0m preds\u001b[39m.\u001b[39mappend(outputs\u001b[39m.\u001b[39msigmoid()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    138\u001b[0m true_labels\u001b[39m.\u001b[39mappend(targets\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "\n",
    "dlt = []\n",
    "empty_fld = [109, 123, 709]\n",
    "df = pd.read_csv(\"./input/train_labels.csv\")\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "X = df['BraTS21ID'].values\n",
    "Y = df['MGMT_value'].values\n",
    "\n",
    "for i in empty_fld:\n",
    "    j = np.where(X == i)\n",
    "    dlt.append(j)\n",
    "    X = np.delete(X, j)\n",
    "    \n",
    "Y = np.delete(Y,dlt)\n",
    "\n",
    "for m in mod:\n",
    "    '''wandb.init(\n",
    "    project=\"Kaggle-LB-1 sanity check\",\n",
    "    notes = \"running sanity check\",\n",
    "    name=f\"experiment_{m}\", \n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"monai resnet10\",\n",
    "    \"dataset\": \"MICAA MRI\",\n",
    "    \"epochs\": N_EPOCHS,\n",
    "    \"Batch size\": TRAINING_BATCH_SIZE\n",
    "    })'''\n",
    "    \n",
    "    print(\"--------------------deleted the empty patient data--------------------------\")\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(Y)), Y), 1):  \n",
    "    \n",
    "        losses = []\n",
    "        train_f_score = []\n",
    "        test_fscore = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        xtrain = X[train_idx]\n",
    "        ytrain = Y[train_idx]\n",
    "        xtest = X[test_idx]\n",
    "        ytest = Y[test_idx]\n",
    "            \n",
    "        print(f\"train_{m}_{fold}\")\n",
    "        \n",
    "        train_dataset = BrainRSNADataset(\n",
    "                                        patient_path='./input/reduced_dataset/',\n",
    "                                        paths=xtrain, \n",
    "                                        targets= ytrain,\n",
    "                                        mri_type=m,\n",
    "                                        ds_type=f\"train_{m}_{fold}\"\n",
    "                                        )\n",
    "    \n",
    "        valid_dataset = BrainRSNADataset(\n",
    "                                        patient_path='./input/reduced_dataset/',\n",
    "                                        paths=xtest,\n",
    "                                        targets=ytest,\n",
    "                                        mri_type=m,\n",
    "                                        is_train=False,\n",
    "                                        ds_type=f\"val_{m}_{fold}\"\n",
    "                                        )\n",
    "        #print(\"----------------------created dataset successfully-------------------------------\")\n",
    "    \n",
    "        train_dl = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAINING_BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=n_workers,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    \n",
    "        validation_dl = torch.utils.data.DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=TEST_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=n_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #print(\"-----------------loaded the dataloader successfully---------------------------\")\n",
    "    \n",
    "        # Checking the dataset\n",
    "        '''for batch in train_dl:  \n",
    "            print('Image batch dimensions:', batch['image'].shape)\n",
    "            print('Image Class dimensions:', batch['target'].shape)\n",
    "            break'''\n",
    "    \n",
    "    \n",
    "        model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "        #print(\"--------------------------loaded the model succeffully-------------------------\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "    \n",
    "        model.zero_grad()\n",
    "        model.to(device)\n",
    "        best_loss = 9999\n",
    "        best_auc = 0\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        #print(\"-------------------------------starting the trianing loop-------------------------\")\n",
    "        train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        train_f1 = torchmetrics.F1Score(task=\"binary\")\n",
    "        \n",
    "        test_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        test_f1 = torchmetrics.F1Score(task=\"binary\")     \n",
    "        \n",
    "        for counter in range(N_EPOCHS):\n",
    "    \n",
    "            #epoch_iterator_train = tqdm(train_dl)\n",
    "            tr_loss = 0.0\n",
    "            preds = []\n",
    "            true_labels = []\n",
    "            #case_ids = []\n",
    "            for step, batch in enumerate(train_dl):\n",
    "                model.train()\n",
    "                images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "                #print(\"feature shape:\", images.shape)\n",
    "                #print(\"targets shape:\", targets.shape)\n",
    "    \n",
    "                outputs = model(images)\n",
    "                targets = targets  # .view(-1, 1)\n",
    "                loss = criterion(outputs.squeeze(1), targets.float())\n",
    "    \n",
    "                #print(\"output shape:\", outputs.shape)\n",
    "                #print(\"targtes shape\", targets.shape)\n",
    "    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                tr_loss += loss.item()\n",
    "                \n",
    "                preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                true_labels.append(targets.cpu().numpy())\n",
    "                #case_ids.append(batch[\"case_id\"])\n",
    "            \n",
    "            preds = np.vstack(preds).T[0].tolist()\n",
    "            true_labels = np.hstack(true_labels).tolist()\n",
    "            #case_ids = np.hstack(case_ids).tolist()\n",
    "            #print(\"preds shape:\", len(preds))\n",
    "            #print(\"true_labels shape:\", len(true_labels))\n",
    "            #print(\"preds:\", preds)\n",
    "            #print(\"true labels:\", true_labels)\n",
    "            _auc_score = roc_auc_score(true_labels, preds)\n",
    "            _acc = train_acc(torch.tensor(preds), torch.tensor(true_labels))\n",
    "            _f1 = train_f1(torch.tensor(preds),torch.tensor(true_labels))\n",
    "    \n",
    "            \n",
    "            '''wandb.log({\n",
    "                'train loss': tr_loss / (step+1),\n",
    "                'train AUC': _auc_score, \n",
    "                'train F1 score': _f1.item(),\n",
    "                'train acc': _acc.item()\n",
    "            })'''\n",
    "    \n",
    "            print(\n",
    "                f\"Train EPOCH {counter+1}/{N_EPOCHS}: average loss: {tr_loss/(step+1)}, Acc: {_acc}, F1 score: {_f1}  AUC SCORE = {_auc_score}\"\n",
    "            )\n",
    "    \n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "    \n",
    "            if do_valid:\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    preds = []\n",
    "                    true_labels = []\n",
    "                    #case_ids = []\n",
    "                    #epoch_iterator_val = tqdm(validation_dl)\n",
    "                    for step, batch in enumerate(validation_dl):\n",
    "                        model.eval()\n",
    "                        images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "    \n",
    "                        #print(\"test features images:\", images.shape)\n",
    "                        #print(\"test targets:\", targets.shape)\n",
    "    \n",
    "                        outputs = model(images)\n",
    "                        targets = targets  # .view(-1, 1)\n",
    "                        #print(\"test outputs:\", outputs.shape)\n",
    "                        #print(\"test targets:\", targets.shape)\n",
    "                        loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                        val_loss += loss.item()\n",
    "                        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                        true_labels.append(targets.cpu().numpy())\n",
    "                        #case_ids.append(batch[\"case_id\"])\n",
    "                preds = np.vstack(preds).T[0].tolist()\n",
    "                true_labels = np.hstack(true_labels).tolist()\n",
    "                #case_ids = np.hstack(case_ids).tolist()\n",
    "                auc_score = roc_auc_score(true_labels, preds)\n",
    "                acc_ = test_acc(torch.tensor(preds), torch.tensor(true_labels))\n",
    "                f1_ = test_f1(torch.tensor(preds),torch.tensor(true_labels))\n",
    "            \n",
    "            '''wandb.log({\n",
    "                'test loss': val_loss / (step+1),\n",
    "                'test AUC': auc_score, \n",
    "                'test F1 score': f1_.item(),\n",
    "                'test acc': acc_.item()\n",
    "            })'''\n",
    "\n",
    "            train_acc.reset()\n",
    "            train_f1.reset()\n",
    "            test_acc.reset()\n",
    "            test_f1.reset()\n",
    "            \n",
    "            auc_score_adj_best = 0\n",
    "            for thresh in np.linspace(0, 1, 50):\n",
    "                auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "                if auc_score_adj > auc_score_adj_best:\n",
    "                    best_thresh = thresh\n",
    "                    auc_score_adj_best = auc_score_adj\n",
    "    \n",
    "            print(\n",
    "                f\"Test EPOCH {counter+1}/{N_EPOCHS}: Validation average loss: {val_loss/(step+1)}, Accuracy: {acc_} F1 score: {f1_}, + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "            )\n",
    "            \n",
    "            if auc_score > best_auc:\n",
    "                print(\"Saving the model...\")\n",
    "    \n",
    "                all_files = os.listdir(\"weights/\")\n",
    "    \n",
    "                for f in all_files:\n",
    "                    if f\"resnet10_{m}_fold{fold}\" in f:\n",
    "                        os.remove(f\"weights/{f}\")\n",
    "    \n",
    "                best_auc = auc_score\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f\"weights/resnet10_{m}_fold{fold}.pth\",\n",
    "                )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    #wandb.finish()\n",
    "    print(\"best auc:\", best_auc)\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaranjot\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/karanjotvendal/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/karanjotvendal/karanjot/thesis/RSNA/3 Establishing baseline result/1/rsna-resnet10/wandb/run-20230820_191228-fhb71alu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexperiment_FLAIR\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/karanjot/Kaggle_LB-1%20sanity%20check\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/karanjot/Kaggle_LB-1%20sanity%20check/runs/fhb71alu\u001b[0m\n",
      "-----------------train_FLAIR_1-------------------\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python ./working/train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
