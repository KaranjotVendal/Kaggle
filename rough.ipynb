{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import glob\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import lr_scheduler\n",
    "import re\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import monai\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_3D = 64\n",
    "TRAINING_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 112\n",
    "N_EPOCHS = 2\n",
    "do_valid = True\n",
    "n_workers = 0\n",
    "type_ = \"FLAIR\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    image = cv2.imread(path, 0)\n",
    "    if image is None:\n",
    "        return np.zeros(IMAGE_SIZE)\n",
    "    \n",
    "    image = cv2.resize(image, size) / 255\n",
    "    return image.astype('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainRSNADataset(Dataset):\n",
    "    def __init__(\n",
    "        self, patient_path, paths, targets, transform=None, mri_type=\"FLAIR\", is_train=True, ds_type=\"forgot\", do_load=True\n",
    "    ):\n",
    "        \n",
    "        self.patient_path = patient_path\n",
    "        self.paths = paths   \n",
    "        self.targets = targets\n",
    "        self.type = mri_type\n",
    "\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.folder = \"train\" if self.is_train else \"test\"\n",
    "        self.do_load = do_load\n",
    "        self.ds_type = ds_type        \n",
    "        \n",
    "        '''self.target = target\n",
    "        self.data = data\n",
    "        self.type = mri_type\n",
    "\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.folder = \"train\" if self.is_train else \"test\" '''\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        target = self.targets[index]\n",
    "        _3d_images = self.load_images_3d(_id)\n",
    "        _3d_images = torch.tensor(_3d_images).float()\n",
    "        if self.is_train:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        else:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''row = self.data.loc[index]\n",
    "        case_id = int(row.BraTS21ID)\n",
    "        target = int(row[self.target])\n",
    "        _3d_images = self.load_dicom_images_3d(case_id)\n",
    "        _3d_images = torch.tensor(_3d_images).float()\n",
    "        if self.is_train:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        else:\n",
    "            return {\"image\": _3d_images, \"case_id\": case_id}'''\n",
    "\n",
    "\n",
    "    def load_images_3d(\n",
    "        self,\n",
    "        case_id,\n",
    "        num_imgs=NUM_IMAGES_3D,\n",
    "        img_size=IMAGE_SIZE,\n",
    "        rotate=0,\n",
    "    ):\n",
    "        case_id = str(case_id).zfill(5)\n",
    "\n",
    "        path = f\"./input/reduced_dataset/{case_id}/{self.type}/*.png\"\n",
    "        files = sorted(\n",
    "            glob.glob(path),\n",
    "            key=lambda var: [\n",
    "                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        middle = len(files) // 2\n",
    "        if len(files) <= 64:\n",
    "            image_stack = [load_image(f) for f in files]\n",
    "        else:\n",
    "            p1 = middle - 32 #max(0, middle - num_imgs2)\n",
    "            p2 = middle + 32 #min(len(files), middle + num_imgs2)\n",
    "            image_stack = [load_image(f) for f in files[p1:p2]]\n",
    "            \n",
    "            \n",
    "            \n",
    "        '''num_imgs2 = num_imgs // 2\n",
    "        p1 = max(0, middle - num_imgs2)\n",
    "        p2 = min(len(files), middle + num_imgs2)\n",
    "        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]'''\n",
    "        \n",
    "        img3d = np.stack(image_stack).T\n",
    "        if img3d.shape[-1] < num_imgs:\n",
    "            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "            img3d = np.concatenate((img3d, n_zero), axis=-1)\n",
    "\n",
    "        if np.min(img3d) < np.max(img3d):\n",
    "            img3d = img3d - np.min(img3d)\n",
    "            img3d = img3d / np.max(img3d)\n",
    "\n",
    "        return np.expand_dims(img3d, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfolds\u001b[0m/  \u001b[01;34mreduced_dataset\u001b[0m/  train_labels.csv\n"
     ]
    }
   ],
   "source": [
    "ls ./input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------deleted the empty patient data--------------------------\n",
      "train_FLAIR_1\n"
     ]
    }
   ],
   "source": [
    "dlt = []\n",
    "empty_fld = [109, 123, 709]\n",
    "df = pd.read_csv(\"./input/train_labels.csv\")\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "X = df['BraTS21ID'].values\n",
    "Y = df['MGMT_value'].values\n",
    "\n",
    "for i in empty_fld:\n",
    "    j = np.where(X == i)\n",
    "    dlt.append(j)\n",
    "    X = np.delete(X, j)\n",
    "    \n",
    "Y = np.delete(Y,dlt)\n",
    "print(\"--------------------deleted the empty patient data--------------------------\")\n",
    "\n",
    "m = \"FLAIR\"\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(Y)), Y), 1):  \n",
    "\n",
    "    losses = []\n",
    "    train_f_score = []\n",
    "    test_fscore = []\n",
    "    start_time = time.time\n",
    "    \n",
    "    xtrain = X[train_idx]\n",
    "    ytrain = Y[train_idx]\n",
    "    xtest = X[test_idx]\n",
    "    ytest = Y[test_idx]\n",
    "        \n",
    "    print(f\"train_{m}_{fold}\")\n",
    "    \n",
    "    train_dataset = BrainRSNADataset(\n",
    "                                    patient_path='./input/reduced_dataset/',\n",
    "                                    paths=xtrain, \n",
    "                                    targets= ytrain,\n",
    "                                    mri_type=m,\n",
    "                                    ds_type=f\"train_{m}_{fold}\"\n",
    "                                    )\n",
    "\n",
    "    valid_dataset = BrainRSNADataset(\n",
    "                                    patient_path='./input/reduced_dataset/',\n",
    "                                    paths=xtest,\n",
    "                                    targets=ytest,\n",
    "                                    mri_type=m,\n",
    "                                    is_train=False,\n",
    "                                    ds_type=f\"val_{m}_{fold}\"\n",
    "                                    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 112, 112, 64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m dlt \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m empty_fld \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m109\u001b[39m, \u001b[38;5;241m123\u001b[39m, \u001b[38;5;241m709\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./input/train_labels.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBraTS21ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "'''mod = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n",
    "\n",
    "for m in mod:\n",
    "    wandb.init(\n",
    "    project=\"try runs 1\", \n",
    "    name=f\"experiment_{m}\", \n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"ResNet10\",\n",
    "    \"dataset\": \"MICAA MRI\",\n",
    "    \"epochs\": N_EPOCHS,\n",
    "    \"Batch size\": TRAINING_BATCH_SIZE\n",
    "    })'''\n",
    "\n",
    "\n",
    "dlt = []\n",
    "empty_fld = [109, 123, 709]\n",
    "df = pd.read_csv(\"./input/train_labels.csv\")\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "X = df['BraTS21ID'].values\n",
    "Y = df['MGMT_value'].values\n",
    "\n",
    "for i in empty_fld:\n",
    "    j = np.where(X == i)\n",
    "    dlt.append(j)\n",
    "    X = np.delete(X, j)\n",
    "    \n",
    "Y = np.delete(Y,dlt)\n",
    "print(\"--------------------deleted the empty patient data--------------------------\")\n",
    "m=\"FLAIR\"\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(np.zeros(len(Y)), Y), 1):  \n",
    "\n",
    "    losses = []\n",
    "    train_f_score = []\n",
    "    test_fscore = []\n",
    "    start_time = time.time\n",
    "    \n",
    "    xtrain = X[train_idx]\n",
    "    ytrain = Y[train_idx]\n",
    "    xtest = X[test_idx]\n",
    "    ytest = Y[test_idx]\n",
    "        \n",
    "    print(f\"train_{m}_{fold}\")\n",
    "    \n",
    "    train_dataset = BrainRSNADataset(\n",
    "                                    patient_path='./input/reduced_dataset/',\n",
    "                                    paths=xtrain, \n",
    "                                    targets= ytrain,\n",
    "                                    mri_type=m,\n",
    "                                    ds_type=f\"train_{m}_{fold}\"\n",
    "                                    )\n",
    "\n",
    "    valid_dataset = BrainRSNADataset(\n",
    "                                    patient_path='./input/reduced_dataset/',\n",
    "                                    paths=xtest,\n",
    "                                    targets=ytest,\n",
    "                                    mri_type=m,\n",
    "                                    is_train=False,\n",
    "                                    ds_type=f\"val_{m}_{fold}\"\n",
    "                                    )\n",
    "    print(\"----------------------created dataset successfully-------------------------------\")\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAINING_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    validation_dl = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=TEST_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"-----------------loaded the dataloader successfully---------------------------\")\n",
    "\n",
    "    # Checking the dataset\n",
    "    for batch in train_dl:  \n",
    "        print('Image batch dimensions:', batch['image'].shape)\n",
    "        print('Image Class dimensions:', batch['target'].shape)\n",
    "        break\n",
    "\n",
    "\n",
    "    model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, num_classes=1)\n",
    "    print(\"--------------------------loaded the model succeffully-------------------------\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.5, last_epoch=-1, verbose=True)\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.to(device)\n",
    "    best_loss = 9999\n",
    "    best_auc = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    print(\"-------------------------------starting the trianing loop-------------------------\")\n",
    "    for counter in range(N_EPOCHS):\n",
    "\n",
    "        epoch_iterator_train = tqdm(train_dl)\n",
    "        tr_loss = 0.0\n",
    "        preds = []\n",
    "        true_labels = []\n",
    "        #case_ids = []\n",
    "        for step, batch in enumerate(epoch_iterator_train):\n",
    "            model.train()\n",
    "            images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "            print(\"feature shape:\", images.shape)\n",
    "            print(\"targets shape:\", targets.shape)\n",
    "\n",
    "            outputs = model(images)\n",
    "            targets = targets  # .view(-1, 1)\n",
    "            loss = criterion(outputs.squeeze(1), targets.float())\n",
    "\n",
    "            print(\"output shape:\", outputs.shape)\n",
    "            print(\"targtes shape\", targets.shape)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_iterator_train.set_postfix(\n",
    "                batch_loss=(loss.item()), loss=(tr_loss / (step + 1))\n",
    "            )\n",
    "\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            true_labels.append(targets.cpu().numpy())\n",
    "            #case_ids.append(batch[\"case_id\"])\n",
    "        \n",
    "        preds = np.vstack(preds).T[0].tolist()\n",
    "        true_labels = np.hstack(true_labels).tolist()\n",
    "        #case_ids = np.hstack(case_ids).tolist()\n",
    "        print(\"preds shape:\", preds.shape)\n",
    "        pritn(\"true_labels shape:\", true_labels.shape)\n",
    "        \n",
    "        auc_score = roc_auc_score(true_labels, preds)\n",
    "        \n",
    "        '''wandb.log({\n",
    "            'train loss': tr_loss / (step+1),\n",
    "            'Train AUC': auc_score, \n",
    "            'Train F1 score': f1_score\n",
    "        })'''\n",
    "\n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter}/{N_EPOCHS}: Train average loss: {tr_loss/(step+1)} +  AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "\n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "\n",
    "            all_files = os.listdir(\"../weights/checkpoints/\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"resnet10_{mod}_fold{fold}\" in f:\n",
    "                    os.remove(f\"../weights/checkpoints/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../weights/chechpoints/resnet10_{mod}_fold{fold}.pth\",\n",
    "            )\n",
    "\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "        if config.do_valid:\n",
    "            model.load_state_dict(torch.load(f\"../weights/checkpoints/resnet10_{m}_fold{fold}\"))           \n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                preds = []\n",
    "                true_labels = []\n",
    "                #case_ids = []\n",
    "                epoch_iterator_val = tqdm(validation_dl)\n",
    "                for step, batch in enumerate(epoch_iterator_val):\n",
    "                    model.eval()\n",
    "                    images, targets = batch[\"image\"].to(device), batch[\"target\"].to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    targets = targets  # .view(-1, 1)\n",
    "                    loss = criterion(outputs.squeeze(1), targets.float())\n",
    "                    val_loss += loss.item()\n",
    "                    epoch_iterator_val.set_postfix(\n",
    "                        batch_loss=(loss.item()), loss=(val_loss / (step + 1))\n",
    "                    )\n",
    "                    preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "                    true_labels.append(targets.cpu().numpy())\n",
    "                    case_ids.append(batch[\"case_id\"])\n",
    "            preds = np.vstack(preds).T[0].tolist()\n",
    "            true_labels = np.hstack(true_labels).tolist()\n",
    "            case_ids = np.hstack(case_ids).tolist()\n",
    "            auc_score = roc_auc_score(true_labels, preds)\n",
    "            \n",
    "        '''wandb.log({'Test AUC': auc_score,\n",
    "                    'Test F1 score': f1_score})'''\n",
    "        \n",
    "        auc_score_adj_best = 0\n",
    "        for thresh in np.linspace(0, 1, 50):\n",
    "            auc_score_adj = roc_auc_score(true_labels, list(np.array(preds) > thresh))\n",
    "            if auc_score_adj > auc_score_adj_best:\n",
    "                best_thresh = thresh\n",
    "                auc_score_adj_best = auc_score_adj\n",
    "\n",
    "        print(\n",
    "            f\"EPOCH {counter}/{config.N_EPOCHS}: Validation average loss: {val_loss/(step+1)} + AUC SCORE = {auc_score} + AUC SCORE THRESH {best_thresh} = {auc_score_adj_best}\"\n",
    "        )\n",
    "        \n",
    "        if auc_score > best_auc:\n",
    "            print(\"Saving the model...\")\n",
    "\n",
    "            all_files = os.listdir(\"../weights/checkpoints/\")\n",
    "\n",
    "            for f in all_files:\n",
    "                if f\"resnet10_{mod}_fold{fold}\" in f:\n",
    "                    os.remove(f\"../weights/checkpoints/{f}\")\n",
    "\n",
    "            best_auc = auc_score\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"../weights/chechpoints/resnet10_{mod}_fold{fold}.pth\",\n",
    "            )\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "'''wandb.log({\n",
    "    'Avg Train loss': np.mean(losses),\n",
    "    'Avg Train F1 Score': np.mean(train_f_score),\n",
    "    'Avg Test F1 Score': np.mean(test_fscore)\n",
    "})'''\n",
    "\n",
    "print(\"best auc:\", best_auc)\n",
    "print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
    "#print('Avg loss {:.5f}'.format(np.mean(losses)))\n",
    "#print('Avg Train f1_score {:.5f}'.format(np.mean(train_f_score)))\n",
    "#print('Avg Test f1_score {:.5f}'.format(np.mean(test_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_true_labels = []\n",
    "tta_preds = []\n",
    "test_dataset = BrainRSNADataset(data=sample, mri_type=type_, is_train=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=8, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "preds_f = np.zeros(len(sample))\n",
    "for fold in range(5):\n",
    "    image_ids = []\n",
    "    model.load_state_dict(torch.load(f\"../input/resnet10rsna/{fold_files[fold]}\"))\n",
    "    preds = []\n",
    "    epoch_iterator_test = tqdm(test_dl)\n",
    "    with torch.no_grad():\n",
    "        for  step, batch in enumerate(epoch_iterator_test):\n",
    "            model.eval()\n",
    "            images = batch[\"image\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            image_ids.append(batch[\"case_id\"].detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "    preds_f += np.vstack(preds).T[0]/5\n",
    "\n",
    "    ids_f = np.hstack(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"BraTS21ID\"] = ids_f\n",
    "sample[\"MGMT_value\"] = preds_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.sort_values(by=\"BraTS21ID\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
